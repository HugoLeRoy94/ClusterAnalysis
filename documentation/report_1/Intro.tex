\section{Introduction}

-> Here, we describe a data-driven procedure to extract stereotypical behavior from animal trajectories.
-> The assumption underlying this procedure is that we use animal centric measurements of the trajectories that reflects the "inner state" of the animal.
-> 
-> However, the state of an animal, and the associated change is not 

\section{Mathematical framework}

\subsection{Preprocessing}
-> We use input trajectories : $Y_\text{in}$ that contains $N_\text{in}$ sample of inhomogeneous trajectories length, in $d$ dimensions, with equal timesteps $\Delta t$.
-> The first step is a smoothing of the  trajectories using a Savitzky-Golay filter, a window of 7 time steps, and a polynome of order 3.
-> Next, we convert these trajectories into homogeneous length. We select a total time $T$, discard trajectories that have a time smaller than $T$, whereas longer trajectories are cut into one or several trajectories of length $T$.
-> At this point, $Y$ is a \texttt{numpy.ndarray} of dimension $N \times Y \times d$ of $(x,y,z)$ positions.
-> We then convert the  $\mathbf{X}(t) = (x(t), y(t), z(t))$: positions into parameters t hat are independant of the reference frame, namely : velocity: $||\textbf{v}||$, rotation velocity $\dot{\theta}$, and torsion velocity $\dot{\phi}$, defined as:
\begin{wrapfigure}[15]{r}{0.35\textwidth} % 'l' for left and '0.5\textwidth' for the width of the figure box
  \centering
  \includegraphics[width=0.3\textwidth]{trajectory_length.pdf} % Width less than the wrapfigure width to ensure padding
  \caption{Distribution of trajectory length, we use $T = 1000$.}
  \label{fig:phase_diagram}
\end{wrapfigure}
\subsubsection*{velocity $|\textbf{v}|$}
\begin{equation}
|\mathbf{v}_i| = \frac{1}{2} \left( \left\| \frac{\mathbf{X}_{i+1} - \mathbf{X}_i}{\Delta t} \right\| + \left\| \frac{\mathbf{X}_{i+2} - \mathbf{X}_{i+1}}{\Delta t} \right\| \right)
\end{equation}
\subsubsection*{Angular velocity $\dot{\theta}_i$}
Define the normalized tangent vectors:
\begin{equation}
\mathbf{T}_i = \frac{\mathbf{X}_{i+1} - \mathbf{X}_i}{\|\mathbf{X}_{i+1} - \mathbf{X}_i\|}
\end{equation}
Then the angle $\theta_i$ between consecutive tangent vectors:
\begin{equation}
\theta_i = \arccos\left( \mathbf{T}_i \cdot \mathbf{T}_{i+1} \right)
\end{equation}
\begin{equation}
\dot{\theta}_i = \frac{\theta_i}{\Delta t}
\end{equation}
\subsubsection*{Torsion rate $\dot{\phi}_i$}

Given two successive normal vectors $\mathbf{n}_i$ and $\mathbf{n}_{i+1}$n we define:

\begin{equation}
\psi_i = \arccos\left( \frac{ \mathbf{n}_i \cdot \mathbf{n}_{i+1} }{ \|\mathbf{n}_i\| \cdot \|\mathbf{n}_{i+1}\| } \right)
\end{equation}
with an optional sign:
\begin{equation}
\psi_i^\text{signed} = \operatorname{sign}\left( (\mathbf{n}_i \times \mathbf{n}_{i+1}) \cdot \mathbf{T}_{i+1} \right) \cdot \psi_i
\end{equation}
Then define torsion rate as:
\begin{equation}
\dot{\psi}_i = \frac{\psi_i}{\Delta t}
\end{equation}

In the following, we use the vector $\textbf{Y} = \left\{ \left[v_t^i,\dot{\theta}_t^i, \dot{\psi}_t^i \right]_{t\in [0,T]}\right\}_i$ where $i$ refeers to the trajectory number, and $t$ the time point.

\subsection{Embedding}

From the input data $\textbf{Y}$, and for each individual trajectory, we build a delayed embedding matrix where each line is a time delayed portion of trajectory of size $K$. Formally, for a given trajectory $i$, we got: 

\begin{equation}
\mathbf{Y}_{K}^i =
\left[
\begin{array}{ccccccc}
y_1(1) & y_2(1) & \cdots & y_d(1) & \cdots & y_1(K) & \cdots y_d(K) \\
y_1(2) & y_2(2) & \cdots & y_d(2) & \cdots & y_1(K+1) & \cdots y_d(K+1) \\
\vdots & \vdots &        & \vdots &        & \vdots & \ddots \vdots \\
y_1(T{-}K{+}1) & y_2(T{-}K{+}1) & \cdots & y_d(T{-}K{+}1) & \cdots & y_1(T) & \cdots y_d(T)
\end{array}
\right]
\quad
\begin{array}{l}
\left. \rule{0pt}{3.5em} \right\} T{-}K{+}1 \text{ rows} \\
\end{array}
\end{equation}
\begin{equation*}
\underbrace{\hspace{12cm}}_{K \cdot d \text{ columns}}
\end{equation*}

Applied to our system, we obtain the following embedding matrix :

\begin{equation}
\mathbf{Y}_{K}^i =
\left[
\begin{array}{cccccccc}
v_1^i & \dot{\theta}_1^i & \dot{\psi}_1^i & \cdots & v_K^i & \dot{\theta}_K^i & \dot{\psi}_K^i \\
v_2^i & \dot{\theta}_2^i & \dot{\psi}_2^i & \cdots & v_{K+1}^i & \dot{\theta}_{K+1}^i & \dot{\psi}_{K+1}^i \\
\vdots & \vdots & \vdots &        & \vdots & \vdots & \vdots \\
v_{T-K+1}^i & \dot{\theta}_{T-K+1}^i & \dot{\psi}_{T-K+1}^i & \cdots & v_T^i & \dot{\theta}_T^i & \dot{\psi}_T^i \\
\end{array}
\right]
\quad
=
\left[
\begin{array}{c}
Y_K^i(1) \\
Y_K^i(2) \\
\vdots \\
Y_K^i(T-K+1)
\end{array}
\right]
\quad
\begin{array}{l}
\left. \rule{0pt}{3.5em} \right\} T{-}K{+}1 \text{ rows}
\end{array}
\end{equation}
\begin{equation}
\underbrace{\hspace{10cm}}_{3K \text{ columns}}
\end{equation}

$Y_K^i$ can be interpreted as a trajectory vector where each data point fits in a space of dimension $3K$.

\subsection{Clustering}

-> We now have a series of highly dimensional vectors, to analyze it, we first clusterize individual points into $N_c$ clusters using a K-means algorithm.
-> We then model the dynamic of the animal through a Markov process, where each cluster defines a state $si$. 
-> Considering trajectories individually, we find transition rates between clusters using:
We build a finite-dimensional approximation of the Perron–Frobenius operator using an Ulam–Galerkin discretization. Given a transition time \( \tau \), we compute the count matrix:
\[
C_{ij}(\tau) = \sum_{t=0}^{T-K+1 - \tau} \zeta_i(Y_{K}^i(t)) \, \zeta_j(Y_{K}^i(t + \tau)),
\]
where \( \zeta_i(x) \) are the Ulam basis functions, defined as the characteristic functions of the partition sets:
\[
\zeta_i(x) =
\begin{cases}
1, & \text{if } x \in s_i, \\
0, & \text{otherwise},
\end{cases}
\]
with \( \{s_i\} \) obtained via \( k \)-means clustering. The maximum likelihood estimator of the transition matrix is obtained by row-normalizing the count matrix:
\[
P_{ij}(\tau) = \frac{C_{ij}(\tau)}{\sum_j C_{ij}(\tau)},
\]
which yields a finite-dimensional approximation of the stochastic matrix $\bar{P}$. There are three free parameters in this procedure : $K$, $N_c$, $\tau$. We now propose a way to optimize them.

\subsection{Parameter optimization}

We first 



\subsection{Predictive }

\subsection{Coarse graining}

Once the free parameters are optimized, we now 



%\begin{lstlisting}
%def foo(x):
%    return x + 1
%\end{lstlisting}

%The function \texttt{def foo(x): return x + 1} defines a simple increment.



